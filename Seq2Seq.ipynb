{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model \n",
    "\n",
    "## - German to English Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "## -----------\n",
    "### I) Preprocessing\n",
    "### II) Encoder, Decoder and Seq2Seq Models\n",
    "### III) Hyperparameters\n",
    "### IV) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Preprocessing\n",
    "\n",
    "Steps:\n",
    "\n",
    "1) Load source(German) and target(English) tokernizers from Spacy.\n",
    "\n",
    "2) Use Field class from torchtext to tokenize, lowercase words, add initial(<sos>) and end of sentence tokens(<eos>).\n",
    "    \n",
    "3) Load source and target sentences using Multi30k from torchtext.\n",
    "    \n",
    "4) Create source and target vocab vectors.\n",
    "    \n",
    "5) Creates batches with source and target data. Also pads the data to create equal length sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)\n",
    "#Load source(German) and target(English) tokernizers from Spacy.\n",
    "spacy_ger = spacy.load('de')\n",
    "spacy_eng = spacy.load('en')\n",
    "\n",
    "def tokenizer_ger(text):\n",
    "    return [token.text for token in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenizer_eng(text):\n",
    "    return[token.text for token in spacy_eng.tokenizer(text)]\n",
    "\n",
    "# 2)\n",
    "#Use Field class from torchtext to tokenize, lowercase words, add initial() \n",
    "#and end of sentence tokens().\n",
    "german = Field(tokenize=tokenizer_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "english = Field(tokenize=tokenizer_eng, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "# 3) \n",
    "#Load source and target sentences using Multi30k from torchtext.\n",
    "train_data, validation_data, test_data = Multi30k.splits(exts=('.de', '.en'),\n",
    "                                                        fields=(german, english))\n",
    "\n",
    "# 4) \n",
    "#Create source and target vocab vectors.\n",
    "#Only words that are present in database at least twice are added to vocab tensor.\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "# 5) \n",
    "#Creates batches with source and target data. Also pads the data to create equal length sentences.\n",
    "#The sort_within_batch and sort_key TRIES to make sure that the batches contain words of equal\n",
    "#length so that it doesn't waste too much compute in padding.\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key= lambda x: len(x.src),\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Encoder, Decoder and Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.a) Encoder\n",
    "\n",
    "Sequentially takes an input(German word) and outputs hidden and cell states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        #input_dim, emb_dim, hid_dim = dimentionalities of the respective tensor.\n",
    "        self.hid_dim = hid_dim\n",
    "        #n_layers = number of RNNs used.\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #nn.Embedding converts the one-hot vectors into dense vectors or embedded vectors.\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        #src = [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #Only hidden and cell tensors are passed to Decoder (output ignored).\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.b) Decoder \n",
    "Takes in hidden and cell state from Encoder, English word (which can be the predicted output from the previous time step or from the target data) and outputs predicted word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size,\n",
    "                num_layers, dropout_layer):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_layer)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_layer)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    #Note here that we are also passing in the hidden and cell state.\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # shape of x: (1, batch size, embedding_size)\n",
    "        #The '1' is because we are sending in a word at a time through the decoder.\n",
    "        #So, to add the '1', we can unsqueeze the array.\n",
    "        x = x.unsqueeze(0)\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, batch size, hidden_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        #shape of outputs: (1, batch size, hidden_size)\n",
    "        \n",
    "        predictions = self.fc(outputs)\n",
    "        # shape predictions: (1, batch size, length_of_vocab)\n",
    "        #When sending it to the fully connected layer, we don't need the '1'\n",
    "        #therefore, we can squeeze it to get rid of the '1'.\n",
    "        predictions = predictions.squeeze(0)\n",
    "        \n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.c) Seq2Seq\n",
    "Combine both Encoder and Decoder here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        \n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        #Grab the start token.\n",
    "        x = target[0]\n",
    "        \n",
    "        #The teacher_force_ratio is applicable to the decoder.\n",
    "        #If you vizualize the decoder, the output here is a sequence of english words.\n",
    "        #The output from one node is going to be the input to the the next.\n",
    "        #However, if the output is the wrong word, this means the input to the next node is wrong as well.\n",
    "        #What we can do to prevent this is feed input from the target sentence into the decoder time to time.\n",
    "        #So 50% of the time, input will be words from the target sequence.\n",
    "        #If it is more, this would then not train the model properly as it is given all the answers.\n",
    "        \n",
    "        #In this for loop, we can see that the parameter to the decoder, 'x', is sometimes target\n",
    "        #and sometimes it is the the word from output.\n",
    "        #We start however with the first word in the target i.e. start token.\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            \n",
    "            outputs[t] = output\n",
    "            \n",
    "            best_guess = output.argmax(1)\n",
    "            \n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "#Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device('cpu')\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "#Tensorboard\n",
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0 / 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "454it [8:40:35, 68.80s/it]  \n"
     ]
    }
   ],
   "source": [
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size,\n",
    "                     num_layers, enc_dropout).to(device)\n",
    "\n",
    "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, \n",
    "                     output_size, num_layers, dec_dropout).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#pad_idex in place of the ignore_index ignores output that is completely padded.\n",
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch} / {num_epochs}]')\n",
    "    \n",
    "    for batch_idx, batch in tqdm(enumerate(train_iterator)):\n",
    "        input_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        \n",
    "        output = model(input_data, target)\n",
    "        #output shape: (target_len, batch_size, output_dim)\n",
    "        \n",
    "        #Decoder loop starts from 1 and not 0 (check above in Decoder model).\n",
    "        #What we get from decoder:\n",
    "        #output = [<sos>, y1, y2, y3, <eos>]\n",
    "        #target = [0, y1^, y2^, y3^]\n",
    "        #What we need: \n",
    "        #output = [y1, y2, y3, <eos>]\n",
    "        #target = [y1^, y2^, y3^]\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Training loss', loss, global_step=step)\n",
    "        step += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
